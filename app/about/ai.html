---
title: Harvard Law AI Summit 2023
slug: ai
layout: simple-page
---

<h1>{{ page.title }}</h1>

<p>
  <em
    >The Library Innovation Lab is bringing together experts who are driving the
    development, adoption, and regulation of AI technology as it rewires society
    and the law along with it.</em
  >
</p>

<p>
  Note: this page is for the Harvard Law AI Summit on September 19, 2023. This
  is an invitation only event.
</p>

<h2>Recommended Readings</h2>
<p>
  We don’t have required readings, but we do have some <a href="https://docs.google.com/document/d/1XNSWdWoAQ-4_r4HzdTsGk8wJmnPB60y1Hr91Devniz4/edit#heading=h.dpq3r4f3vvga">interesting
  suggestions</a>,
  many of them written by conference participants. Feel free to skim and check
  out anything that catches your eye. We will be updating the list as we receive
  additional suggestions.
</p>

<h2>Guest List</h2>
<p>
  As this is an invitation-only gathering with an aim to create connections, we
  are sharing the guest list with all participants. This <a href="(https://docs.google.com/spreadsheets/d/1mm7HwnyaOjaE57J1K12vNb-iq5vZ7wrzmhfys7T-oFs/edit#gid=1268423724">participant
  list</a>
  is public for attendees during the summit and will be emailed to you after the event. The participant list is not for publication.
</p>

<hr />

<h2>AI Projects at LIL</h2>
<p><strong>These projects are all in progress, if you’d like to keep up with them please <a href="https://law.us3.list-manage.com/subscribe?u=4290964398813d739f2398db0&id=e097736c6f">subscribe to our newsletter.</a></strong></p>
<p>
  Generative AI offers a defining moment where information archives gain the
  ability to answer questions about themselves; to act without human
  intervention; and even to simulate the processes that created them.
  From our perspective at the lab - where we bring library principles to
  technological frontiers - anyone who is concerned with information, access,
  and the law should be aware of and feel empowered to influence the use of
  generative AIs. We have embarked upon a series of projects in support of that
  belief.
</p>

<p>
  In addition to the Harvard Law AI Summit, here’s what else we’ve been up to at
  LIL:
</p>

<h3>Collaborative Open Legal Data (COLD) Dataset</h3>
<p>
  The legal nonprofit <a href="https://free.law/">Free Law Project</a> maintains a wide variety of web crawlers 
to collect and publish an ever-growing dataset of public domain law at
  <a href="http://courtlistener.com/">CourtListener.com</a>.
</p>

<p>
  The Library Innovation lab has assembled this data into a dataset suitable for
  machine learning and made it available on
  <a href="https://huggingface.co/datasets/harvard-lil/cold-cases"
    >HuggingFace</a
  >, along with a
  <a
    href="https://datanutrition.org/labels/v3/?id=c29976b2-858c-4f4e-b7d0-c8ef12ce7dbe"
    >Data Nutrition Label</a
  >
  which explains the source of the data and gives guidelines for ethical use.
  The result is information about over 8 million court cases are available for
  batch processing, for example in the context of data science and AI
  experiments.
</p>

<h3>One Million Books</h3>
<p>
  Building on our work on the COLD Dataset, we are working with the Harvard Libraries to identify more public domain datasets that can support computational research and AI experimentation for the public good. One project underway would release a large cache of digitized books and accurate metadata, in collaboration with library technologists and with researchers exploring data set consent and bias issues.
</p>

<h3>Caselaw Access Project and the Right to Access Edicts of Law</h3>
<p>
  In 2017, the Harvard Law Library kicked off the Caselaw Access Project (CAP),
  by digitizing 360 years of U.S. case law. The Library Innovation Lab (LIL)
  transformed it into the largest U.S. legal database of its time. Much of this
  data is public and discoverable for free on LIL's site
  <a href="https://case.law">case.law.</a>
</p>

<p>
  At the end of February 2024 this collection will go fully open as a dataset structured for reading by humans and machines. We are collaborating with friends at Lexis Nexis, Fastcase, and the Free Law Project to ensure the maximum social benefit to this launch. We expect part of the launch will include a public declaration and call for a human right to access the edicts of law.
</p>

<h3>Open French Law Chatbot</h3>
<p>This experiment explores whether an open-source LLM (Llama 2) can act as both translator and French law expert if provided with the entirety of French codes as a vector database. The case study will delve into the potential and limitations of open-source LLMs and associated toolchains, and to what extent embedding models and vector databases can augment and “ground” the responses provided by LLMs. In addition, LIL will publish the embeddings database containing the entirety of French law. 
 </p>

 <h3>Model Academic Research Agreement</h3>
 <p>We have drafted and are seeking initial partners for a Model Academic Research Agreement, which would make it easier, faster, and safer for academic researchers to provide advice on unreleased products and models, benefiting both academia and industry.</p>

<h3>Library Data Trust</h3>
<p>Research into speculative funding structures for libraries and their
collections. The Library Data Trust would set up a structure whereby libraries
and archives digitized their collections and made them available for a fee to
commercial users and for free to everyone else. The goals would be to make more
collections available to more people while securing the financial future of
libraries.</p>

<h3>LLMs and Book Ban Benchmark</h3>
<p>Are LLMs champions of the freedom to read? The impetus of this experiment was
the news that an
<a href="https://www.popsci.com/technology/iowa-chatgpt-book-ban/"
  > Iowa school district relied on ChatGPT’s responses to determine which books
  to remove from the library.</a> We asked five different LLMs to provide a
  justification for removing Toni Morrison’s The Bluest Eye from library shelves
  with the objective of demonstrating how “guardrails” differ among models and
  assessing the impact of altering the temperature parameter. About 75% of the
  responses across all five LLMs justified removing the book from library
  shelves. The case study will be published as part of Banned Books Week in
  October.
</a>
</p>

<h3>LIL Vector</h3>
<p>lil_vector is our community server for experimenting with generative AI technology. Located in LIL space, this machine learning server allows us to freely explore the potential of open-source AI models. </p>

<p>
  But more than a shared compute resource, it is a nascent community hub on which technologists from LIL and beyond share resources and experiments, as we collectively make sense of this AI moment. 
</p>

<h2>Harvard Library Innovation Lab AI Fund </h2>
<p>To support this and other work, we have launched a LIL AI Fund to accept gifts and coordinate collaboration with law firms, legal technologists, foundations, and others working at the cutting edge of law, AI, libraries, and society. Contact us to discuss participation.</p>